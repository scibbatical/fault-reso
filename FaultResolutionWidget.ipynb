{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Seismic Modelling\n",
    "## Exploring Fault Resolution\n",
    "\n",
    "To start, you should read [THE BLOG POST].\n",
    "\n",
    "When you're done reading, replicate a reflector you're familiar with, then test some of your assumptions about visibility of fault offset. How much offset could a fault accumulate while still appearing as a \"flexure\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get started - Set up this workspace:\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bruges # pip install bruges     installs a great library from Agile Scientific\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "from skimage.util import random_noise\n",
    "\n",
    "from ipywidgets import FloatSlider, IntSlider, fixed, FloatLogSlider, interactive #interact, interact_manual, IntText,\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.patches as patches\n",
    "from statistics import pvariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from LEtools.py\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    # find the index of nearest sample to a given value\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def LEthink(depthlog, log, start, end, adjustment):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Log Edit Thin/Thick\n",
    "    \n",
    "    returns depthout, logout\n",
    "    \n",
    "    depthlog - the depth log - assumed to be an MD log, but may work for TVD?\n",
    "    log - the log which is to be modified\n",
    "    start - the top of the interval which is to be modified IN DEPTH\n",
    "    end - the end of the interval which is to be modified IN DEPTH\n",
    "    adjustment - quanitfies the amount of thickness change to be imposed (positive is thickening)\n",
    "    \"\"\"\n",
    "    \n",
    "    if adjustment != 0:\n",
    "        \n",
    "        # Find the indecies of the samples that define the top and bottom of adjustment interval:\n",
    "        start_i = find_nearest(depthlog,start)\n",
    "        end_i = find_nearest(depthlog,end)\n",
    "\n",
    "\n",
    "        # Create depthlog for new interval\n",
    "\n",
    "        # Find the depthlog sample rate\n",
    "        deltad = depthlog[1]-depthlog[0]\n",
    "\n",
    "        # Create new depthlog for interval\n",
    "        depthinterval = np.arange(start,end+adjustment,deltad)\n",
    "\n",
    "\n",
    "        # Create adjusted log for new interval\n",
    "\n",
    "        # Extract the portion of the log to be adjusted\n",
    "        loginterval = log[start_i:end_i]\n",
    "\n",
    "        # Interpolate/resample\n",
    "        #logintersamp = np.interp(np.arange(start,end,(end-start)/(end_i-start_i+(adjustment/deltad))),depthlog[start_i:end_i],loginterval)\n",
    "        logintersamp = np.interp(np.arange(start,end,(end-start)/len(depthinterval)),depthlog[start_i:end_i],loginterval)\n",
    "\n",
    "        # Ensure length of output logs is the same... squeezing logs sometimes caused a problem\n",
    "        if len(logintersamp)!= len(depthinterval):\n",
    "            logintersamp = logintersamp[:-1]\n",
    "\n",
    "\n",
    "        # Create new depthlog for output\n",
    "        depthout = np.append(np.append(depthlog[:start_i],depthinterval),depthlog[end_i:]+adjustment*np.ones_like(depthlog[end_i:]))\n",
    "\n",
    "        # Create new log for output\n",
    "        logout = np.append(np.append(log[:start_i],logintersamp),log[end_i:])\n",
    "\n",
    "        return depthout,logout\n",
    "    \n",
    "    else:\n",
    "        return depthlog,log\n",
    "\n",
    "def LEdepthtime(log,timedepthlog,timesamplerate):\n",
    "    \"\"\"\n",
    "    \n",
    "    Log Edit Depth to Time\n",
    "    \n",
    "    returns timelog, logout\n",
    "    \n",
    "    log - the log which is to be converted to time\n",
    "    timedepthlog - the log of cumulative time at regular depths\n",
    "    timesamplerate - the desired sample rate of the new log (in seconds, often 0.002)\n",
    "    \"\"\"\n",
    "    \n",
    "    tmax = (np.amax(timedepthlog)//0.25+1)*0.25 # rounds to the nearest 0.25 seconds\n",
    "    \n",
    "    # Create the timelog\n",
    "    timelog = np.arange(0, tmax, timesamplerate) # Creates the log into which values are interpolated\n",
    "    \n",
    "    # Interpolate the log\n",
    "    logtime = np.interp(timelog,timedepthlog,log)\n",
    "    \n",
    "    return timelog, logtime\n",
    "\n",
    "def logs2RC_t(depthlog,density,sonic,timesamplerate,depthsamplerate=0.2,vreplacement=2000):\n",
    "    '''\n",
    "    For now, only input density and sonic logs. Other logs may be added later!\n",
    "    \n",
    "    returns a time log, sonic log, and a reflectivity series\n",
    "    \n",
    "    depthlog : the depth log\n",
    "    density : the density log, used to calculate the impedance\n",
    "    sonic : the sonic log, used to calculate the impedance\n",
    "    timesamplerate : the desired samplerate for the output (in seconds, often 0.002)\n",
    "    depthsamplerate : the samplerate of the logs from the LAS file (in meters, often 0.2)\n",
    "    vreplacement : the assumed velocity above the top of the sonic log (meters/second)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # Calculate the time-depth relationship\n",
    "    # Convert DT to travel time per sample, then create a running total\n",
    "    cumtime = 2 * np.cumsum(depthsamplerate/1e6 * np.nan_to_num(sonic))\n",
    "    # Account for the time above the shallowest measurement\n",
    "        # Find shallowest non-zero sonic measurement, convert that depth to time via\n",
    "        # replacement velocity, then add that value to cumtime values.\n",
    "    timedepth = (2 * depthlog[np.amin(np.where(cumtime[:] != 0))]/vreplacement) + cumtime\n",
    "    \n",
    "    # Convert logs from depth to time\n",
    "    timelog, density_t = LEdepthtime(density,timedepth,timesamplerate)\n",
    "    timelog, sonic_t = LEdepthtime(sonic,timedepth,timesamplerate)\n",
    "    \n",
    "    # Calculate impedance log\n",
    "    impedance_t = 1e6*(density_t/sonic_t)\n",
    "    \n",
    "    # Calculate the reflectivity series\n",
    "    reflectivity_t = (impedance_t[1:] - impedance_t[:-1]) / (impedance_t[1:] + impedance_t[:-1])\n",
    "    \n",
    "    return timelog[:-1], sonic_t, reflectivity_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get started - Create synthetic sonic and density logs for a well.\n",
    "\n",
    "# Density Log\n",
    "DEN = np.zeros(500)\n",
    "DEN[:250] = 2300\n",
    "DEN[250:] = 2500\n",
    "\n",
    "# Sonic Log\n",
    "DT = np.zeros_like(DEN)\n",
    "DT[:250] = 375 # ~2650 m/s\n",
    "DT[250:] = 350 # ~2850 m/s\n",
    "\n",
    "# Depth track\n",
    "DEPTH = np.array(np.arange(0,100,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fault_model(freq,f_offset,noise_var,lat_smooth,DEPTH,DEN,DT,dt=0.001,len_wav=0.2):\n",
    "    \"\"\"\n",
    "    Function to demonstrate the visibility of faults. Generates a plot.\n",
    "    \n",
    "       \n",
    "    #corner_freqs  =  list of four corner frequencies for Ormsby wavelet [f1,f2,f3,f4]\n",
    "    freq          =  central frequency of Ricker wavelet\n",
    "    f_offset      =  vertical offset of the modelled fault\n",
    "    noise_var     =  variance of random noise (= (standard deviation)**2). Best >> 1\n",
    "    lat_smooth    =  lateral smoothing defined as standard deviation for gaussian kernal.\n",
    "    DEPTH         =  Depth log\n",
    "    DEN           =  Density log\n",
    "    DT            =  Sonic log\n",
    "    dt            =  sample rate in seconds for modelling and wavelet (default=0.001)\n",
    "    len_wav       =  length in seconds for wavelet (default = 0.2)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the wavelet\n",
    "\n",
    "    wav = bruges.filters.wavelets.ricker(duration=len_wav,dt=dt,f=freq)\n",
    "    wavelength = np.sqrt(6)/(np.pi*freq)* 1e6 /DT[0] /2\n",
    "\n",
    "    # Create a new time series for the wavelet - may not use it, but it's here\n",
    "    Twavestart = -(len_wav/dt-1)/2 * dt\n",
    "    Twaveend = (len_wav/dt-1)/2 * dt\n",
    "\n",
    "    Twav = np.arange(Twavestart,Twaveend+dt,dt)\n",
    "\n",
    "    # Use a Bag of Really Useful Geophysical Stuff to calculate the spectrum of the un-interpolated wavelet:\n",
    "    spec = bruges.attribute.spectrogram(wav,len(wav)-1,zero_padding=100)[0]\n",
    "\n",
    "    # Calculate the Nyquist frequency from the sample rate:\n",
    "    nyq = 0.5 * (1/dt) # samplerate is in seconds\n",
    "    \n",
    "    \n",
    "    # Run TIME\n",
    "    \n",
    "    # Run this to create a time log. We're not interested in the time log, per se,\n",
    "    # but it is required to run the flow\n",
    "    TIME,DT_t,RC_t = logs2RC_t(DEPTH,DEN,DT,dt)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "\n",
    "    # Initialize an array to hold the wedge:\n",
    "    secRC = np.array([[]])\n",
    "    secDT = np.array([[]])\n",
    "    secDT_time = np.array([[]])\n",
    "\n",
    "    # Define left side of model\n",
    "    for i in range(0,40):\n",
    "\n",
    "        # Modify logs - not changing these traces    \n",
    "        # Thicken the DT log between 0m and 10m by 0m\n",
    "        depth_interim, DT_interim = LEthink(DEPTH,DT,0,10,0)\n",
    "        depth_interim, DEN_interim = LEthink(DEPTH,DEN,0,10,0)\n",
    "\n",
    "        # Calculate reflectivity in time\n",
    "        # Use Log Edit tools to calculate Reflectivity Coefficients and convert trace to time\n",
    "        time_interim, DT_time, RC_interim = logs2RC_t(depth_interim,\n",
    "                                                              DEN_interim,\n",
    "                                                              DT_interim,dt)\n",
    "\n",
    "        # Append to section as new trace\n",
    "        if i == 0: # if-else is used to deal with the case array is empty\n",
    "            secRC = np.append(secRC,[RC_interim[:len(TIME)]],axis=1)\n",
    "            secDT = np.append(secDT,[DT_interim[:len(DEPTH)]],axis=1)\n",
    "            secDT_time = np.append(secDT_time,[DT_time[:len(TIME)]],axis=1)\n",
    "        else:\n",
    "            secRC = np.append(secRC,[RC_interim[:len(TIME)]],axis=0)\n",
    "            secDT = np.append(secDT,[DT_interim[:len(DEPTH)]],axis=0)\n",
    "            secDT_time = np.append(secDT_time,[DT_time[:len(TIME)]],axis=0)\n",
    "\n",
    "\n",
    "    # Define right side of model\n",
    "    for i in range(0,40):\n",
    "\n",
    "        # Modify logs - add extra thickness to top of log    \n",
    "        # Thicken the DT log between 0m and 10m by fault offset\n",
    "        depth_interim, DT_interim = LEthink(DEPTH,DT,0,10,f_offset)\n",
    "        depth_interim, DEN_interim = LEthink(DEPTH,DEN,0,10,f_offset)\n",
    "\n",
    "        # Calculate reflectivity in time\n",
    "        # Use Log Edit tools to calculate Reflectivity Coefficients and convert trace to time\n",
    "        time_interim, DT_time, RC_interim = logs2RC_t(depth_interim,\n",
    "                                                              DEN_interim,\n",
    "                                                              DT_interim,dt)\n",
    "\n",
    "        # Append to section as new trace\n",
    "        secRC = np.append(secRC,[RC_interim[:len(TIME)]],axis=0)\n",
    "        secDT = np.append(secDT,[DT_interim[:len(DEPTH)]],axis=0)\n",
    "        secDT_time = np.append(secDT_time,[DT_time[:len(TIME)]],axis=0)\n",
    "\n",
    "        \n",
    "    # Add noise - I found adding noise before convolution with the wavelet\n",
    "    #             created more realistic results.\n",
    "    \n",
    "    # Add noise to RC model:\n",
    "    secRC_noise = random_noise(secRC, mode='gaussian', var=noise_var)\n",
    "\n",
    "       \n",
    "    # Convolve with wavelet\n",
    "    \n",
    "    # Initialize empty array\n",
    "    sec_fault_synth = np.zeros_like(secRC_noise)\n",
    "    # Populate array with reflectivity amplitude\n",
    "    for i in range(secRC.shape[0]):\n",
    "        sec_fault_synth[i,:] = np.convolve(wav, np.nan_to_num(secRC_noise[i,:]), mode='same')\n",
    "\n",
    "    # Extract the max amplitude from the synthetic - used for scaling plots\n",
    "    synthAMPmax = 1.0 * max(np.amax(sec_fault_synth),abs(np.amin(sec_fault_synth)))\n",
    "    \n",
    "    \n",
    "    # Lateral smoothing - gaussian smoothing applied across each time sample\n",
    "    \n",
    "    sec_fault_synth_filt = gaussian(sec_fault_synth,\n",
    "                                      sigma=[lat_smooth,0], mode='reflect',\n",
    "                                      preserve_range=True)\n",
    "    \n",
    "    \n",
    "    # Calculate signal to noise ratio\n",
    "    \n",
    "    #SNR = Variance(signal) / (Variance(signal + noise) - Variance(signal))\n",
    "    # Need Variance of signal, and coveniently the variance of one trace\n",
    "    # is same as whole section\n",
    "    var_signal = pvariance(np.convolve(wav, np.nan_to_num(secRC[0]), mode='same'))\n",
    "    \n",
    "    # Now calculate the ratio                       \n",
    "    snr = var_signal / (pvariance(sec_fault_synth_filt.tolist()[0])- var_signal)\n",
    "    \n",
    "    \n",
    "    # Plot spectrogram, model in depth, model in time, final synthetic\n",
    "    \n",
    "    #Plot Wavelet\n",
    "    #fig = plt.figure(figsize=(12,12))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,2))\n",
    "    ax[0].plot(Twav,wav,c='k',linewidth=3, alpha=0.5)\n",
    "    ax[0].axhline(y=0, c='k')\n",
    "    ax[0].set_title('Ricker Wavelet')\n",
    "    ax[0].set_xlabel('Time [s]')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    ax[0].grid()\n",
    "\n",
    "    # plot the histogram\n",
    "    ax[1].plot(np.arange(0,nyq,nyq/len(spec)),spec, c='k',linewidth=3, alpha=0.5)\n",
    "    ax[1].set_yscale('log')\n",
    "    ax[1].set_xlim(0,3*freq)\n",
    "    ax[1].set_ylim(bottom = 0.002)\n",
    "    ax[1].set_title('Wavelet Frequency Spectrum')\n",
    "    ax[1].set_xlabel('Frequency [Hz]')\n",
    "    ax[1].set_ylabel('Amplitude')\n",
    "    ax[1].grid()\n",
    "\n",
    "    # Second half of composite is created as new figure!\n",
    "    # Sonic in time\n",
    "    fig2, ax = plt.subplots(1, 2, sharey=True, figsize=(10,6))\n",
    "    im = ax[0].imshow(secDT_time[:,:75].T, vmin=340, vmax=410,\n",
    "                   cmap=\"viridis_r\", aspect='auto')\n",
    "    ax[0].yaxis.set_ticks_position(\"both\")\n",
    "    #ax[0].yaxis.set_label_position(\"right\")\n",
    "    ax[0].set_yticks(range(0,71,10))\n",
    "    ax[0].set_yticklabels(np.arange(0,71*dt, 10*dt))\n",
    "    ax[0].set_title('Section: Slowness')\n",
    "    ax[0].set_ylabel('Time [ms]')\n",
    "    ax[0].set_xlabel('trace')\n",
    "    #ax[0].axvline(x=40, linestyle='--', color='k')\n",
    "    cbar = fig.colorbar(im, ax=ax[0],ticks=range(200,401,50),orientation='horizontal')\n",
    "    cbar.ax.invert_xaxis()\n",
    "    cbar.set_label('slowness [usec/m]')\n",
    "    \n",
    "    # Add some text:\n",
    "    ax[1].text(-40,-20,'Fault offset is ' + r'$\\lambda/ %s$' % np.round(wavelength/f_offset,1), fontsize=15)\n",
    "    ax[1].text(-40,-10,'Signal to noise ratio is %s' % np.round(snr,2), fontsize=15)\n",
    "\n",
    "    # Wavelet seismic in time\n",
    "    #ax = fig.add_subplot(236)\n",
    "    im = ax[1].imshow(sec_fault_synth_filt[:,:75].T,\n",
    "                   vmin=-synthAMPmax, vmax=synthAMPmax,\n",
    "                   cmap=\"seismic\", aspect='auto')\n",
    "    ax[1].set_yticks(range(0,71,10))\n",
    "    ax[1].set_yticklabels(np.arange(0,71*dt, 10*dt))\n",
    "    ax[1].set_title('Section: Reflectivity')\n",
    "    #ax[1].set_ylabel('Time [ms]')\n",
    "    ax[1].set_xlabel('trace')\n",
    "    #ax[1].axvline(x=40, linestyle='--', color='k')\n",
    "    cbar = fig.colorbar(im, ax=ax[1], ticks=[-.1,0,.1], orientation='horizontal')\n",
    "    cbar.set_label('reflectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = interactive(fault_model, freq=IntSlider(min=10, max=150, step=2, description='Frequency', value=60, continuous_update=False),\n",
    "                   f_offset=IntSlider(min=0, max=20, step=1, description='Fault Offset', value = 10, continuous_update=False),\n",
    "                   noise_var=FloatLogSlider(value=0.001, base=10, min=-6, max=-1, description='Noise Var.', continuous_update=False),\n",
    "                   lat_smooth=IntSlider(min=0, max=10, step=1, value=3, description='Lat. Smooth', continuous_update=False),\n",
    "                   DEPTH=fixed(DEPTH), DEN=fixed(DEN), DT=fixed(DT),\n",
    "                   dt=fixed(0.001),len_wav=fixed(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60aef911d5d64939b2822fc58fdb786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=60, continuous_update=False, description='Frequency', max=150, min=10, s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rslt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "How much vertical offset must a fault accumulate to become recognizable on a seismic section? Studies of seismic's ability to resolve thin beds have established well-known limits for resolution: Widess criterion specifies an eighth wavelength; Raleigh Criterion specifies a quarter wavelength. However, neither of these are really applicable to the visibility of a fault. This widget allows you to explore fault visibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A website built out of a Jupyter notebook using Voila!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for Python and the libraries used here:\n",
    "\n",
    "Hall, M., Bianco, E., Bougher, B., et al. (2013- ). Bruges: a bag of really useful geophysical equations and stuff (Python module), https://github.com/agile-geoscience/bruges, [online; accessed 2017-05-01]\n",
    "Hunter, J. D. (2007), Matplotlib: A 2D graphics environment, Computing in Science & Engineering, 9, 90-95, doi:10.1109/MCSE.2007.55\n",
    "\n",
    "Jones, E., Oliphant, E., Peterson, P., et al., (2001- ). SciPy: Open Source Scientific Tools for Python, http://www.scipy.org/, [online; accessed 2018-09-01].\n",
    "\n",
    "Pérez, F., & Granger, B. E. (2007). IPython: A System for Interactive Scientific Computing, Computing in Science & Engineering, 9, 21-29, doi:10.1109/MCSE.2007.53\n",
    "\n",
    "van der Walt, S., Colbert, S. C., Varoquaux, G. (2011). The NumPy Array: A Structure for Efficient Numerical Computation, Computing in Science & Engineering, 13, 22-30, doi:10.1109/MCSE.2011.37\n",
    "\n",
    "Stéfan van der Walt, Johannes L. Schönberger, Juan Nunez-Iglesias, François Boulogne, Joshua D. Warner, Neil Yager, Emmanuelle Gouillart, Tony Yu and the scikit-image contributors. scikit-image: Image processing in Python. PeerJ 2:e453 (2014) https://doi.org/10.7717/peerj.453\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
